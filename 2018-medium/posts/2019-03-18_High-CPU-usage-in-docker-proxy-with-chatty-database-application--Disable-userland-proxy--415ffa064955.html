<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>High CPU usage in docker-proxy with chatty database application? Disable userland-proxy!</title><style>
      * {
        <!--font-family: Georgia, Cambria, "Times New Roman", Times, serif;-->
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">High CPU usage in docker-proxy with chatty database application? Disable userland-proxy!</h1>
</header>
<section data-field="subtitle" class="p-summary">
Or just keep database and application co-located :)
</section>
<section data-field="body" class="e-content">
<section name="383f" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="7dea" id="7dea" class="graf graf--h3 graf--leading graf--title">High CPU usage in docker-proxy with chatty database application? Disable userland-proxy!</h3><h4 name="79d0" id="79d0" class="graf graf--h4 graf-after--h3 graf--subtitle">Or just keep database and application co-located :)</h4><p name="3236" id="3236" class="graf graf--p graf-after--h4">It is well-known from the get-go, but very often overlooked because of ignorance or laziness: <strong class="markup--strong markup--p-strong">the database application must be co-located with the database server</strong>. Row-by-row roundtrips between the application and the database are expensive. Not only due to the network latency, but also because of the many CPU cycles wasted to switch the context between the two engines, or the two processes, and maybe the two servers.</p><p name="1706" id="1706" class="graf graf--p graf-after--p">In modern architectures, with microservices and containers, this means that a business service must be implemented in one microservice containing the business logic and the business data. Separating the application and the database into two microservices is a wrong design, non-efficient, non-scalable, and also non-green because of the unnecessary CPU usage.</p><h4 name="1c0b" id="1c0b" class="graf graf--h4 graf-after--p">Docker</h4><p name="9b3b" id="9b3b" class="graf graf--p graf-after--h4">I was building a new demo for this, as in the <a href="https://medium.com/@FranckPachot/sql-pl-sql-and-javascript-running-in-the-database-server-oracle-mle-a7a102e1e5ce" data-href="https://medium.com/@FranckPachot/sql-pl-sql-and-javascript-running-in-the-database-server-oracle-mle-a7a102e1e5ce" class="markup--anchor markup--p-anchor" target="_blank">previous post</a>, where I compare running the procedural code in the client or the server side of the database. When I was running my database in a Docker container, I’ve seen that the bad performance I wanted to show was even worse than expected:</p><ul class="postList"><li name="7189" id="7189" class="graf graf--li graf-after--p">the symptom was high CPU usage in “docker-proxy” process</li><li name="fcde" id="fcde" class="graf graf--li graf-after--li">the cause was that I’m using the default Docker userland proxy</li></ul><p name="8c33" id="8c33" class="graf graf--p graf-after--li">Here is the related Twitter thread. Thanks to <a href="http://twitter.com/G_Ceresa" data-href="http://twitter.com/G_Ceresa" class="markup--anchor markup--p-anchor" title="Twitter profile for @G_Ceresa" rel="noopener" target="_blank">@G_Ceresa</a>, <a href="http://twitter.com/ochoa_marcelo" data-href="http://twitter.com/ochoa_marcelo" class="markup--anchor markup--p-anchor" title="Twitter profile for @ochoa_marcelo" rel="noopener" target="_blank">@ochoa_marcelo</a>, and <a href="https://twitter.com/ofirm" data-href="https://twitter.com/ofirm" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">@ofirm</a> for the quick replies about the cause and solution:</p><figure name="f6c9" id="f6c9" class="graf graf--figure graf--iframe graf-after--p"><blockquote class="twitter-tweet"><a href="https://twitter.com/FranckPachot/status/1106983942052368385"></a></blockquote><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></figure><p name="45b4" id="45b4" class="graf graf--p graf-after--figure">This post is a replay of the issue, with PostgreSQL as the database and PgBench as the client application. There’s a summary at the end, but I like to show all the steps.</p><h3 name="38fa" id="38fa" class="graf graf--h3 graf-after--p">Setup with PostgreSQL</h3><p name="1801" id="1801" class="graf graf--p graf-after--h3">I got the issue with an Oracle database, but I reproduced it with PostgreSQL. I start with a default docker 18.09 installation on CentOS 7.6 and 4 cores.</p><pre name="31cd" id="31cd" class="graf graf--pre graf-after--p">yum -y install docker-ce<br>systemctl start docker</pre><p name="e81a" id="e81a" class="graf graf--p graf-after--pre">I have the following docker-compose to get a client and server container:</p><pre name="7fca" id="7fca" class="graf graf--pre graf-after--p">version: &#39;3.1&#39;<br>services:<br>  server:<br>    image: postgres:latest<br>    restart: always<br>    environment:<br>      POSTGRES_PASSWORD: demo<br>      POSTGRES_DB: postgres<br>      POSTGRES_INITDB_ARGS:<br>      POSTGRES_INITDB_WALDIR:<br>      PGDATA: /var/lib/postgresql/data<br>    ports:<br>      - 5432:5432<br>  client:<br>    image: postgres:latest<br>    restart: always<br>    environment:<br>      PGPASSWORD: demo<br>    links:<br>      - server</pre><p name="6408" id="6408" class="graf graf--p graf-after--pre">In addition to that, as I want to run the clinet (pgbench) from outside, I’ve installed it on the host:</p><pre name="50dd" id="50dd" class="graf graf--pre graf-after--p">yum install -y postgresql-contrib</pre><p name="3c3b" id="3c3b" class="graf graf--p graf-after--pre">I create the containers and initialize PgBench with a small database so that everything is in memory as I don’t want I/O latency there:</p><pre name="deef" id="deef" class="graf graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">docker-compose</strong> -f crosscontainerpgbench <strong class="markup--strong markup--pre-strong">up</strong> -d --remove-orphans<br>docker exec -i crosscontainerpgbench_server_1 psql -U postgres -e &lt;&lt;&#39;SQL&#39;<br>drop database if exists demo;<br>create database demo;<br>SQL<br>docker exec -i crossconainerpgbench_server_1 <strong class="markup--strong markup--pre-strong">pgbench -i -s 5</strong> -U postgres demo</pre><h3 name="7f7c" id="7f7c" class="graf graf--h3 graf-after--pre">Test with pgbench — default Docker configuration</h3><p name="e45f" id="e45f" class="graf graf--p graf-after--h3">I’ll simply run a select-only (I don’t want disk I/O in order to have predictable results) workload with 5 clients:</p><pre name="8df2" id="8df2" class="graf graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">pgbench</strong> <strong class="markup--strong markup--pre-strong">-c 5</strong> -j 1 -t 100000 <strong class="markup--strong markup--pre-strong">-S</strong> -M prepared</pre><p name="6ed0" id="6ed0" class="graf graf--p graf-after--pre">I’ll run that from:</p><ul class="postList"><li name="e54b" id="e54b" class="graf graf--li graf-after--p">the DB server container, as if all is embedded in the same service</li><li name="2382" id="2382" class="graf graf--li graf-after--li">the client container, as if I have two containers for DB and application</li><li name="dbb8" id="dbb8" class="graf graf--li graf-after--li">the host, like when the application is running outside of the docker server</li></ul><p name="ec04" id="ec04" class="graf graf--p graf-after--li">I’ll compare the transactions per second, and have a look at the CPU usage.</p><h4 name="60c7" id="60c7" class="graf graf--h4 graf-after--p">Application in the same container</h4><p name="e455" id="e455" class="graf graf--p graf-after--h4">Here is the run from the database server container:</p><pre name="290c" id="290c" class="graf graf--pre graf-after--p">+ docker exec -i crosscontainerpgbench_<strong class="markup--strong markup--pre-strong">server</strong>_1 pgbench -c 5 -j 1 -t 100000 -S -M prepared <strong class="markup--strong markup--pre-strong">-h localhost</strong> -U postgres demo</pre><pre name="3ab7" id="3ab7" class="graf graf--pre graf-after--pre">starting vacuum...end.<br>transaction type: &lt;builtin: select only&gt;<br>scaling factor: 5<br>query mode: prepared<br>number of clients: 5<br>number of threads: 1<br>number of transactions per client: 100000<br>number of transactions actually processed: 500000/500000<br>latency average = 0.286 ms<br>tps = 17510.332823 (including connections establishing)<br><strong class="markup--strong markup--pre-strong">tps = 17512</strong>.433838 (excluding connections establishing)</pre></div><div class="section-inner sectionLayout--outsetColumn"><figure name="56ab" id="56ab" class="graf graf--figure graf--layoutOutsetCenter graf-after--pre"><div class="aspectRatioPlaceholder is-locked" style="max-width: 1032px; max-height: 120px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 11.700000000000001%;"></div><img class="graf-image" data-image-id="1*EVdC2ZStFNWGoJVQA0kSQg.png" data-width="1773" data-height="207" src="https://cdn-images-1.medium.com/max/1200/1*EVdC2ZStFNWGoJVQA0kSQg.png"></div></figure></div><div class="section-inner sectionLayout--insetColumn"><h4 name="96b1" id="96b1" class="graf graf--h4 graf-after--figure">Application in another container</h4><p name="5b11" id="5b11" class="graf graf--p graf-after--h4">Here is the run from the client container through a network link to the server one:</p><pre name="b3d2" id="b3d2" class="graf graf--pre graf-after--p">+ docker exec -i crossconainerpgbench_<strong class="markup--strong markup--pre-strong">client</strong>_1 pgbench -c 5 -j 1 -t 100000 -S -M prepared <strong class="markup--strong markup--pre-strong">-h server</strong> -U postgres demo<br>starting vacuum...end.<br>transaction type: &lt;builtin: select only&gt;<br>scaling factor: 5<br>query mode: prepared<br>number of clients: 5<br>number of threads: 1<br>number of transactions per client: 100000<br>number of transactions actually processed: 500000/500000<br>latency average = 0.358 ms<br>tps = 13964.823706 (including connections establishing)<br><strong class="markup--strong markup--pre-strong">tps = 13966</strong>.547260 (excluding connections establishing)</pre><p name="9e75" id="9e75" class="graf graf--p graf-after--pre">This is a lower transaction per second rate when not running from the same container.</p></div><div class="section-inner sectionLayout--outsetColumn"><figure name="8a98" id="8a98" class="graf graf--figure graf--layoutOutsetCenter graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 1032px; max-height: 135px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 13.100000000000001%;"></div><img class="graf-image" data-image-id="1*ddD083cbz34Pv0xjSVVFnw.png" data-width="1776" data-height="232" src="https://cdn-images-1.medium.com/max/1200/1*ddD083cbz34Pv0xjSVVFnw.png"></div></figure></div><div class="section-inner sectionLayout--insetColumn"><h4 name="fe51" id="fe51" class="graf graf--h4 graf-after--figure">Application outside of any container</h4><p name="fc37" id="fc37" class="graf graf--p graf-after--h4">Here is the run from the host where the 5432 port is exposed:</p><pre name="ed5e" id="ed5e" class="graf graf--pre graf-after--p">+ pgbench -c 5 -j 1 -t 100000 -S -M prepared -h <strong class="markup--strong markup--pre-strong">localhost </strong>-U postgres demo<br>starting vacuum...end.<br>transaction type: SELECT only<br>scaling factor: 5<br>query mode: prepared<br>number of clients: 5<br>number of threads: 1<br>number of transactions per client: 100000<br>number of transactions actually processed: 500000/500000<br>tps = 10803.986896 (including connections establishing)<br><strong class="markup--strong markup--pre-strong">tps = 10810</strong>.876728 (excluding connections establishing)</pre><p name="825e" id="825e" class="graf graf--p graf-after--pre">this is very bad performance when compared to the previous ones. Here is what TOP is sowing during the execution:</p></div><div class="section-inner sectionLayout--outsetColumn"><figure name="ad58" id="ad58" class="graf graf--figure graf--layoutOutsetCenter graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 1032px; max-height: 130px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 12.6%;"></div><img class="graf-image" data-image-id="1*HqdA1xLwZxGDirNXxY97Pw.png" data-width="1910" data-height="240" src="https://cdn-images-1.medium.com/max/1200/1*HqdA1xLwZxGDirNXxY97Pw.png"></div></figure></div><div class="section-inner sectionLayout--insetColumn"><p name="cc5b" id="cc5b" class="graf graf--p graf-after--figure">This docker-proxy is a userland proxy implemented by Docker. It is obviously not efficient given the amount of CPU resource required to just copy the network messages between processes.</p><h3 name="fbf7" id="fbf7" class="graf graf--h3 graf-after--p">Test with pgbench —without the Docker proxy</h3><p name="afa7" id="afa7" class="graf graf--p graf-after--h3">Now, thanks to the replies to my tweet, I got this default (legacy) behavior explained. Docker runs this process as a workaround for old bugs, but we can disable it.</p><p name="9771" id="9771" class="graf graf--p graf-after--p">I’ve added the following in /etc/docker/daemon.json and restarted docker:</p><pre name="1e91" id="1e91" class="graf graf--pre graf-after--p"><code class="markup--code markup--pre-code">{<br>    &quot;userland-proxy&quot;: false<br>}</code></pre><p name="b9ee" id="b9ee" class="graf graf--p graf-after--pre">Now, the port redirection is ensured by iptables only:</p><pre name="6aae" id="6aae" class="graf graf--pre graf-after--p"># iptables -t nat -L -n -v | grep NAT</pre><pre name="6829" id="6829" class="graf graf--pre graf-after--pre">    0     0 <strong class="markup--strong markup--pre-strong">DNAT</strong>       tcp  --  !br-86c9e5013bd1 *       0.0.0.0/0            0.0.0.0/0            tcp dpt:<strong class="markup--strong markup--pre-strong">5432 </strong>to:172.21.0.2:<strong class="markup--strong markup--pre-strong">5432</strong></pre><p name="c6fa" id="c6fa" class="graf graf--p graf-after--pre">Yes, as scary as it sounds, docker can manipulate your iptables without asking you. Remember that you run it as root… so be careful.</p><p name="977c" id="977c" class="graf graf--p graf-after--p">Now, same tests as before…</p><h4 name="8338" id="8338" class="graf graf--h4 graf-after--p">Application in the same container</h4><p name="399c" id="399c" class="graf graf--p graf-after--h4">From the database server container itself:</p><pre name="9a89" id="9a89" class="graf graf--pre graf-after--p">+ docker exec -i crossconainerpgbench_<strong class="markup--strong markup--pre-strong">server</strong>_1 pgbench -c 5 -j 1 -t 100000 -S -M prepared -h localhost -U postgres demo<br>starting vacuum...end.<br>transaction type: &lt;builtin: select only&gt;<br>scaling factor: 5<br>query mode: prepared<br>number of clients: 5<br>number of threads: 1<br>number of transactions per client: 100000<br>number of transactions actually processed: 500000/500000<br>latency average = 0.274 ms<br>tps = 18218.661669 (including connections establishing)<br><strong class="markup--strong markup--pre-strong">tps = 18220</strong>.944898 (excluding connections establishing)</pre><h4 name="6de1" id="6de1" class="graf graf--h4 graf-after--pre">Application in another container</h4><p name="5442" id="5442" class="graf graf--p graf-after--h4">From the client container:</p><pre name="5cea" id="5cea" class="graf graf--pre graf-after--p">+ docker exec -i crossconainerpgbench_<strong class="markup--strong markup--pre-strong">client</strong>_1 pgbench -c 5 -j 1 -t 100000 -S -M prepared -h <strong class="markup--strong markup--pre-strong">server</strong> -U postgres demo<br>starting vacuum...end.<br>transaction type: &lt;builtin: select only&gt;<br>scaling factor: 5<br>query mode: prepared<br>number of clients: 5<br>number of threads: 1<br>number of transactions per client: 100000<br>number of transactions actually processed: 500000/500000<br>latency average = 0.323 ms<br>tps = 15497.325700 (including connections establishing)<br><strong class="markup--strong markup--pre-strong">tps = 15499</strong>.077232 (excluding connections establishing)</pre><h4 name="8d0e" id="8d0e" class="graf graf--h4 graf-after--pre">Application outside of any container</h4><p name="3d35" id="3d35" class="graf graf--p graf-after--h4">From the host, without the userland proxy. Note that I use the IPv4 address for localhost here because where connecting to localhost iptable was dropping the packets:</p><pre name="b0e0" id="b0e0" class="graf graf--pre graf-after--p">+ pgbench -c 5 -j 1 -t 100000 -S -M prepared -h <strong class="markup--strong markup--pre-strong">127.0.0.1</strong> -U postgres demo<br>starting vacuum...end.<br>transaction type: SELECT only<br>scaling factor: 5<br>query mode: prepared<br>number of clients: 5<br>number of threads: 1<br>number of transactions per client: 100000<br>number of transactions actually processed: 500000/500000<br>tps = 16540.617239 (including connections establishing)<br><strong class="markup--strong markup--pre-strong">tps = 16552</strong>.098558 (excluding connections establishing)</pre><p name="baaa" id="baaa" class="graf graf--p graf-after--pre">This is correct, even better than when running from another container, but of course lower than when running in the same container.</p><h3 name="d058" id="d058" class="graf graf--h3 graf-after--p">In summary…</h3><p name="7155" id="7155" class="graf graf--p graf-after--h3">There’s a huge difference when this ‘docker-proxy’ is not running in the middle. Now, all pgbench runs are in the same ballpark, within 10%.</p><p name="bc58" id="bc58" class="graf graf--p graf-after--p">I have run the same tests in a loop in order to get an average. First, here is the standard deviation that I prefer to check because I’m not familiar enough with pgbench (and docker) performance predictability:</p><figure name="c120" id="c120" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 113px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 16.1%;"></div><img class="graf-image" data-image-id="1*qfVBNFRSiUZ50rkZ6ub5Tg.png" data-width="1135" data-height="183" src="https://cdn-images-1.medium.com/max/800/1*qfVBNFRSiUZ50rkZ6ub5Tg.png"></div><figcaption class="imageCaption">Standard Deviation for the preceding results</figcaption></figure><p name="88ae" id="88ae" class="graf graf--p graf-after--figure">And here the results showing the average transactions-per-second with both settings for the docker proxy, and with different colocation of pgbench and DB server: on the docker host in blue, in a different docker container in orange, within the same container in green:</p><figure name="0896" id="0896" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 382px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 54.6%;"></div><img class="graf-image" data-image-id="1*WhsuCP6J8p98lSHItCmK_A.png" data-width="776" data-height="424" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*WhsuCP6J8p98lSHItCmK_A.png"></div><figcaption class="imageCaption">PgBench TPS depending on colocation with the DB and userland proxy</figcaption></figure><p name="4832" id="4832" class="graf graf--p graf-after--figure">It looks like keeping the default value for ‘userland-proxy’ is never good. It forces all external network communication to go through this inefficient process. The performance here slows down to 40% when connecting from outside.</p><p name="f9a4" id="f9a4" class="graf graf--p graf-after--p">The most important is that even with the ‘userland proxy’ disabled, we see a 10% degradation when not running the application in the same container as the database. There’s no magic: the more physical layers you add, the worst performance you get. It can be a small overhead (when the layer is an optimal virtualization) or a huge waste of CPU cycles. Microservices and logical layers are good for the development organization. But when it comes to the platform dependent implementation, colocation is the key to scalability. Build small services, but run them colocated: either the database is embedded in the container, or the procedural code is executed in the database.</p><p name="91aa" id="91aa" class="graf graf--p graf-after--p">I’m talking about this at Riga Dev Days — “Microservices: Get Rid of Your DBA and Send the DB into Burnout”:</p><div name="d6b3" id="d6b3" class="graf graf--mixtapeEmbed graf-after--p"><a href="https://medium.com/@RigaDevDays/sql-sessions-at-rigadevdays-bad9dcc63aca" data-href="https://medium.com/@RigaDevDays/sql-sessions-at-rigadevdays-bad9dcc63aca" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://medium.com/@RigaDevDays/sql-sessions-at-rigadevdays-bad9dcc63aca"><strong class="markup--strong markup--mixtapeEmbed-strong">SQL Sessions at RigaDevDays</strong><br><em class="markup--em markup--mixtapeEmbed-em">Revolution of SQL, Databases, Oracle technologies, Microservices, Performance tricks and more</em>medium.com</a><a href="https://medium.com/@RigaDevDays/sql-sessions-at-rigadevdays-bad9dcc63aca" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="dbddd816a33bd4d662f2015d33708839" data-thumbnail-img-id="1*q_RvBbpiS8v64djzW7zY0A.jpeg" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*q_RvBbpiS8v64djzW7zY0A.jpeg);"></a></div><p name="13c7" id="13c7" class="graf graf--p graf-after--mixtapeEmbed graf--trailing">Feel free to comment on Twitter <a href="https://twitter.com/franckpachot" data-href="https://twitter.com/franckpachot" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">https://twitter.com/franckpachot</a></p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@FranckPachot" class="p-author h-card">Franck Pachot</a> on <a href="https://medium.com/p/415ffa064955"><time class="dt-published" datetime="2019-03-18T17:31:03.112Z">March 18, 2019</time></a>.</p><p><a href="https://medium.com/@FranckPachot/high-cpu-usage-in-docker-proxy-with-chatty-database-application-disable-userland-proxy-415ffa064955" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on July 27, 2019.</p></footer></article></body></html>