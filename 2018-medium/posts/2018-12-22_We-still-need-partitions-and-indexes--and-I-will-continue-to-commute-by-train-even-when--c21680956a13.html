<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>We still need partitions and indexes, and I will continue to commute by train even when…</title><style>
      * {
        <!--font-family: Georgia, Cambria, "Times New Roman", Times, serif;-->
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">We still need partitions and indexes, and I will continue to commute by train even when…</h1>
</header>
<section data-field="subtitle" class="p-summary">
When the Autonomous Data Warehouse Cloud Service had been announced, Oracle came with this surprising idea that we do not need to create…
</section>
<section data-field="body" class="e-content">
<section name="e235" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="0768" id="0768" class="graf graf--h3 graf--leading graf--title">We still need indexes, and I will continue to commute by train even when self-driving cars become reality…</h3><p name="f894" id="f894" class="graf graf--p graf-after--h3">When the Autonomous Data Warehouse Cloud Service had been announced, Oracle came with this surprising idea that we do not need to create Indexes, Partitions and Materialized views for our analytic queries. It was even blocked in ADW and recently released but not recommended. Automatic indexing is for ATP and the message for ADW is: you don’t need indexes for your analytic queries.</p><p name="62b0" id="62b0" class="graf graf--p graf-after--p">In my opinion, and even with the best performance in non-index access, we will still need index range scans. And even when it is not the fastest access path. Because the fastest response time is not the first performance criteria for the end-user.</p><h3 name="1001" id="1001" class="graf graf--h3 graf-after--p">Full Table Scan vs. Index access</h3><p name="b881" id="b881" class="graf graf--p graf-after--h3">Here is a diagram I used to explain the cost of Full Table Scan vs. Index Access, depending on the number of rows to return.</p><figure name="7475" id="7475" class="graf graf--figure graf--layoutOutsetLeft graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 525px; max-height: 308px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 58.699999999999996%;"></div><img class="graf-image" data-image-id="1*qv8lw7bL61t39f6nZ89QNA.png" data-width="1253" data-height="736" data-is-featured="true" src="https://cdn-images-1.medium.com/max/600/1*qv8lw7bL61t39f6nZ89QNA.png"></div><figcaption class="imageCaption">FTS vs. Index cost / number of rows</figcaption></figure><p name="9d52" id="9d52" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">Full Table Scan</strong> depends only on the size of the table. It has the same cost to return zero, one, half, or all the rows. <strong class="markup--strong markup--p-strong">Index Access</strong> is linearly proportional to the number of rows. The optimizer has a hard job to determine the point of inflection. And anyway, around the point of inflection, no method is really optimal. I always recommend providing structures that make one of those two access paths obviously the best.</p><p name="0059" id="0059" class="graf graf--p graf-after--p">The idea of the Autonomous Data Warehouse is to lower the cost of the Full Table Scan, thanks to a combination of hardware and software optimizations. Of course, it cannot be lowered to compete with an index unique access retrieving one row, like for OLTP ‘select * where PK=’. But the inflection point can be moved down enough so that Full Table Scan response time is correct for any analytic query. Then, with only one access method, the optimizer job is easier, less prone to errors. We don’t have to design indexes, and all this can be branded as autonomous tuning.</p><figure name="1fee" id="1fee" class="graf graf--figure graf--layoutOutsetLeft graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 525px; max-height: 215px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 40.9%;"></div><img class="graf-image" data-image-id="1*SEA4t-Dofc2jWSbW7xrbLA.png" data-width="1974" data-height="808" src="https://cdn-images-1.medium.com/max/600/1*SEA4t-Dofc2jWSbW7xrbLA.png"></div><figcaption class="imageCaption">Markus Winand — <a href="https://use-the-index-luke.com/" data-href="https://use-the-index-luke.com/" class="markup--anchor markup--figure-anchor" rel="nofollow noopener" target="_blank">https://use-the-index-luke.com/</a></figcaption></figure><p name="dc28" id="dc28" class="graf graf--p graf-after--figure">Before going to the problem of having no indexes to range scan, I’ll try to summarize quickly the properties of Full Table Scans and Index access. There’s also an excellent read to go into the detail: <a href="https://use-the-index-luke.com/" data-href="https://use-the-index-luke.com/" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">https://use-the-index-luke.com/</a> by Markus Winand.</p><p name="5ee1" id="5ee1" class="graf graf--p graf-after--p">There are two access paths to read table rows:</p><ul class="postList"><li name="c567" id="c567" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Full Table Scan</strong>, which is always available (at the exception of IOTs - Index Organized Tables, as there’s no table) where <strong class="markup--strong markup--li-strong">all</strong> the formatted <strong class="markup--strong markup--li-strong">blocks</strong> of a Heap table are read, <strong class="markup--strong markup--li-strong">without a specific order</strong>.</li><li name="c279" id="c279" class="graf graf--li graf-after--li">Access by ROWID where a <strong class="markup--strong markup--li-strong">sorted</strong> structure (as an Index) or <strong class="markup--strong markup--li-strong">hash</strong> function provides the physical address where to get the <strong class="markup--strong markup--li-strong">rows we need</strong>, without having to scan all blocks.</li></ul><p name="4ce6" id="4ce6" class="graf graf--p graf-after--li">Full Table Scan is efficient because it can to read rows as it is physically the most efficient: contiguous blocks, in large I/O calls, in parallel, asynchronous, bypassing all caches. However, it has to read a lot more than needed. Without any determined order. Then the rows have to be filtered out later. And often sorted or hashed later, to be joined, ordered or deduplicated. Many features have improved Full Table Scan to keep it efficient even when we do not need a lot of rows: Storage Indexes, Zone Maps, SmartScan, Compression, Column Store, In-Memory, HCC,… Those features keep Full Table Scans still efficient for analytic queries where we query only a subset of rows and columns.</p><p name="624a" id="624a" class="graf graf--p graf-after--p">Yes, Full Table Scan on ADW is fast. But from my experience, ‘fast’ response time is not the most important criteria for the end-user. They want predictable response time.</p><h3 name="3b64" id="3b64" class="graf graf--h3 graf-after--p">Users prefer predictability over fast response time</h3><p name="1297" id="1297" class="graf graf--p graf-after--h3">You may think that <strong class="markup--strong markup--p-strong">Full Table Scan</strong> is predictable. That’s because you know the size of the table. But the end-user doesn’t know if the table is compressed, or full of free space. They do not realize how it can be longer when requesting the result to be ordered. They do not understand that querying today’s orders is not faster than querying the whole week. They cannot predict the response time because it is not proportional to the result they expect.</p><p name="d182" id="d182" class="graf graf--p graf-after--p">And there’s more: when many people run the same Full Table Scan, even when expecting different data, they are in competition and all response time will be longer because of buffer busy waits. When you query at a time where there’s a lot of activity on the storage, the response time will also be longer. All this cannot be predicted by the end-user. And the improvements such as Storage Index, In-Memory, Compression,… are not predictable by nature as they depend on the activity. They adapt from the previous queries and concurrent workload.</p><p name="201d" id="201d" class="graf graf--p graf-after--p">Even when <strong class="markup--strong markup--p-strong">Index Access</strong> response time is higher, it stays more predictable because it processes only the required rows. The time will be the same when the table grows by 200%. Or when 5 users are running similar queries. The cost is proportional to the number of rows returned: the end-user will accept easily that querying one week takes x7 more time than for one day. If it takes 5 minutes, they will manage it because they expect this longer duration. They don’t want the fastest response time, they just want a predictable time.</p><figure name="c490" id="c490" class="graf graf--figure graf--layoutOutsetLeft graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 525px; max-height: 309px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 58.9%;"></div><img class="graf-image" data-image-id="1*33U5lFjEbN4LdSQbfjwT1A.png" data-width="1059" data-height="624" src="https://cdn-images-1.medium.com/max/600/1*33U5lFjEbN4LdSQbfjwT1A.png"></div><figcaption class="imageCaption">Autonomous Optimization as presented by Larry Ellison</figcaption></figure><p name="ea6c" id="ea6c" class="graf graf--p graf-after--figure">The features of the Oracle Autonomous Database are presented with an analogy with cars, to push on the self-driving idea. For OLTP, with the Autonomous Transaction Processing, Oracle develops Automatic Indexing. And the analogy is: <em class="markup--em markup--p-em">indexes are like new roads</em>. The optimizer evaluates the execution plans (<em class="markup--em markup--p-em">plans are like driving directions</em>) with the goal to choose the one with the fastest response time. There’s no decision about the most predictable, the one which is less subject to contention with others, or the one which has a response time proportional to the result set. The CBO chose the lower cost, and the <strong class="markup--strong markup--p-strong">CBO</strong> <strong class="markup--strong markup--p-strong">cost is the estimated response time</strong>. With this goal, an <strong class="markup--strong markup--p-strong">optimized table scan looks the best</strong>.</p><p name="07dd" id="07dd" class="graf graf--p graf-after--p">But my goal, keeping the <strong class="markup--strong markup--p-strong">response time predictable by the end-user</strong>, is different. I’ll continue the analogy with the cars. Here is what Google Maps estimates for my morning commute to work:</p><figure name="0cd2" id="0cd2" class="graf graf--figure graf--layoutOutsetLeft graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 525px; max-height: 303px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 57.599999999999994%;"></div><img class="graf-image" data-image-id="1*S-jmL3GViei8YyGA735fpQ.png" data-width="2318" data-height="1336" src="https://cdn-images-1.medium.com/max/600/1*S-jmL3GViei8YyGA735fpQ.png"></div></figure><h4 name="fd65" id="fd65" class="graf graf--h4 graf-after--figure">Car: 35 min — 1 h 5 min</h4><p name="e9f3" id="e9f3" class="graf graf--p graf-after--h4">This is how ‘predictable’ is the commute by car at that time - the peak hour around Geneva. Typically between 35 and 65 minutes. It is, on average, faster than the train. But the time is not linearly proportional to the kilometers. Most of the time is spent in the few ‘red’ kilometers. That’s my analogy with Full Table Scan. We can drive fast, very fast. But the time it takes to reach the destination is uncertain.</p><p name="fc69" id="fc69" class="graf graf--p graf-after--p">And here is what Google Maps estimates for the same commute by train:</p><figure name="18f3" id="18f3" class="graf graf--figure graf--layoutOutsetLeft graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 525px; max-height: 291px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 55.400000000000006%;"></div><img class="graf-image" data-image-id="1*js83rPghaRfiq7KFEAryag.png" data-width="2014" data-height="1116" src="https://cdn-images-1.medium.com/max/600/1*js83rPghaRfiq7KFEAryag.png"></div></figure><h4 name="0cf4" id="0cf4" class="graf graf--h4 graf-after--figure">Train: 1 h — 1 h 1 min</h4><p name="e5c7" id="e5c7" class="graf graf--p graf-after--h4">This is completely predictable, proportional to the distance, and with nearly no variations. Index Access is like my commute by train: most of the time not faster than driving, but finally preferable because of its stability and predictability. And with good design, Index Access can be as precise as Swiss trains ;)</p><p name="e959" id="e959" class="graf graf--p graf-after--p">You can guess that I take the train to go to work. I don’t care that’s it takes longer, because I know it and can manage it — like opening my laptop and writing a blog post — so that it is not wasted time. And I know exactly when I’ll arrive at work for a meeting, or at home to pick up the kids.</p><h3 name="fe20" id="fe20" class="graf graf--h3 graf-after--p">Index, partitions, materialized views</h3><p name="ef59" id="ef59" class="graf graf--p graf-after--h3">If predictability is your first criteria, then your optimization should not rely on caches, parallelism, compression, storage indexes, in-memory population, result cache,… Of course, all these features are welcome when they kick-in at execution time, but they will not help you to forecast a predictable response time. The predictable optimizations are those for which the cost is proportional to the expected result, where we can forecast performance:</p><ul class="postList"><li name="cbc5" id="cbc5" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Partitions</strong> clearly reduce the cost of Full Table Scan with something predictable. The partition pruning has a business meaning. If the user queries a specific time range or geographical area, she knows that the time to retrieve will be proportional to it. Partitions, when properly designed, also keep the cost independent from the table growth.</li><li name="9fca" id="9fca" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Materialized views</strong> give this end-user predictability for aggregations. When a user queries for the monthly amount of sales in the year, she expects a 12 rows result, and she may not imagine that millions of rows have to be scanned for this. With a materialized summary, the response time will meet the volume of the result.</li><li name="5274" id="5274" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Indexes</strong>, when properly designed, will range scan exactly the values required for the query. And they will not add additional time for sorting or deduplicating the rows. Index access will give the best user experience because the retrieval is proportional to the cost imagined by the user. And <strong class="markup--strong markup--li-strong">Top-N queries</strong> is an important part of analytic queries. Only an <strong class="markup--strong markup--li-strong">index range</strong> scan answer a Top-N query without reading all the rows.</li></ul><p name="dab0" id="dab0" class="graf graf--p graf-after--li">Index access is preferable when we query a limited number of rows. Full Table Scan is better when we need to read a large part of the table. The optimizer can choose the best one, but it is based on estimations. If you are in the area around the inflection point, you have the risk of execution plan change between two plans that are not optimal. This is where Cardinality Feedback can be good or bad. You should never leave critical queries in this zone. In the diagram at the top of this post, there’s a dotted line for ‘<strong class="markup--strong markup--p-strong">covering index</strong>’ which pushes the inflection point to a cardinality where it is still an alternative to FTS for a high number of rows. This is when the index contains all required columns and there’s no need to go to the table (and no dependency with the clustering factor, which is difficult to predict by the end-user).</p><h3 name="8304" id="8304" class="graf graf--h3 graf-after--p"><strong class="markup--strong markup--h3-strong">In my opinion</strong></h3><p name="1bad" id="1bad" class="graf graf--p graf-after--h3">With the price of a limited human-labor index design, we can provide <strong class="markup--strong markup--p-strong">speed</strong> and <strong class="markup--strong markup--p-strong">predictability</strong> to our users. Expensive hardware and software can compete with the former, but not the latter. And this is why I think we will always need indexes. The reason is the same as why I prefer to commute by train: predictability of the time.</p><p name="a9e7" id="a9e7" class="graf graf--p graf-after--p graf--trailing">By the way, there’s another reason after predictability and speed: <strong class="markup--strong markup--p-strong">green computing</strong>. Look at the resource (CPU and I/O) usage efficiency and guess which execution plan has the lower carbon footprint. Full Table Scan in Parallel Query, like all the trendy Big Data solutions where you scale by adding more nodes, is awesome and fast, but extremely expensive on resources. Indexes, when correctly designed, will read only what is needed to get the result, with predictable response time.</p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@FranckPachot" class="p-author h-card">Franck Pachot</a> on <a href="https://medium.com/p/c21680956a13"><time class="dt-published" datetime="2018-12-22T18:10:54.973Z">December 22, 2018</time></a>.</p><p><a href="https://medium.com/@FranckPachot/we-still-need-partitions-and-indexes-and-i-will-continue-to-commute-by-train-even-when-c21680956a13" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on July 27, 2019.</p></footer></article></body></html>